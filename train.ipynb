{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import base64\n",
    "import random\n",
    "import chardet\n",
    "import codecs\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from re import sub\n",
    "from collections import defaultdict\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_x(path, dv, max_count = None):\n",
    "    f = open(path, \"r\")\n",
    "    \n",
    "    p = f.readline().decode('utf-8')\n",
    "    \n",
    "    dict_list = []\n",
    "    l_id = 0\n",
    "    while p != '':\n",
    "#         print l_id, len(dict_list)\n",
    "        current = split.get_features(p, max_count)\n",
    "        dict_list  += current\n",
    "        \n",
    "        p = f.readline().decode('utf-8')\n",
    "        l_id += 1\n",
    "    \n",
    "    \n",
    "    \n",
    "    return dv.fit_transform(dict_list), dv, dv.vocabulary_\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_y(path, max_count = None):\n",
    "    f = open(path, \"r\")\n",
    "    result = []\n",
    "   \n",
    "    \n",
    "    p = f.readline()\n",
    "    \n",
    "    total_read = 0\n",
    "    l_id = 0\n",
    "    while p != '':\n",
    "        p = json.loads(p)\n",
    "        tmp = []\n",
    "     \n",
    "        for sentence in p[\"Sentences\"]:\n",
    "            n = sentence.count('.')\n",
    "            if sentence[-1] == '.':\n",
    "                n -= 1\n",
    "            tmp += [0] * n\n",
    "            if sentence[-1] == '.':\n",
    "                tmp.append(1)\n",
    "            total_read += n\n",
    "        \n",
    "            \n",
    "            if max_count is not None and total_read >= max_count:\n",
    "                return np.array(result)\n",
    "        \n",
    "#         if l_id == 77:\n",
    "#             print tmp\n",
    "#             for sentence in p[\"Sentences\"]:\n",
    "#                 print sentence\n",
    "#                 n = sentence.count('.')\n",
    "#                 print n\n",
    "#                 print sentence[-1]\n",
    "#                 if sentence[-1] == '.':\n",
    "#                     n -= 1\n",
    "# #                     tmp += [0] * n\n",
    "#                 print n\n",
    "                \n",
    "            \n",
    "#         print l_id\n",
    "#         print tmp\n",
    "#         print p[\"Paragraph\"]\n",
    "#         print l_id, len(result)\n",
    "        result += tmp\n",
    "        \n",
    "        p = f.readline()\n",
    "        l_id += 1\n",
    "            \n",
    "    \n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'split' from 'split.py'>"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import split\n",
    "reload(split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x, dv, vocab = read_x(\"gold.txt\", DictVectorizer(sparse=False), max_count=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y = read_y(\"gold.json\", max_count = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "380"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(380, 11)"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0.,    0.,    0.,   62.,    1.,    0.,    0.,    0.,    0.,\n",
       "           0.,    1.],\n",
       "       [   0.,    0.,    1.,    9.,    1.,    9.,    0.,    0.,   60.,\n",
       "           1.,    1.],\n",
       "       [   0.,    0.,    7.,  104.,    1.,    1.,    0.,    0.,    7.,\n",
       "           1.,    1.],\n",
       "       [   0.,    0.,    6.,   10.,    1.,   13.,    0.,    0.,  102.,\n",
       "           1.,    1.],\n",
       "       [   0.,    0.,    1.,    3.,    0.,    3.,    0.,    0.,    8.,\n",
       "           1.,    1.],\n",
       "       [   0.,    0.,    1.,  108.,    0.,    1.,    0.,    0.,    1.,\n",
       "           0.,    1.],\n",
       "       [   0.,    0.,   10.,  108.,    1.,   12.,    0.,    0.,  106.,\n",
       "           0.,    1.],\n",
       "       [   0.,    1.,   13.,    1.,    0.,   11.,    0.,    0.,  106.,\n",
       "           1.,    0.],\n",
       "       [   0.,    0.,    0.,  160.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    1.],\n",
       "       [   0.,    0.,   13.,  113.,    1.,   22.,    0.,    0.,  158.,\n",
       "           0.,    1.]])"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score \n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model = DecisionTreeClassifier()\n",
    "model = GradientBoostingClassifier(n_estimators=2500, subsample=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = cross_val_score(model, x, y, cv = 5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.93421053  0.94736842  0.93421053  0.96052632  0.96052632]\n",
      "0.947368421053\n"
     ]
    }
   ],
   "source": [
    "print scores\n",
    "print scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = model.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle.dump(model, open(\"model.pickle\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(dv, open(\"vectorizer.pickle\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_importances(model, vocab):\n",
    "    order = (-model.feature_importances_).argsort()\n",
    "#     print vocab\n",
    "    for i in order:\n",
    "        print vocab.keys()[i], model.feature_importances_[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_elipsis 0.90149463561\n",
      "prev_starts_upper 0.0344367404271\n",
      "is_end 0.0215026472968\n",
      "next_is_upper= 0.0182089052459\n",
      "len 0.0100111483177\n",
      "last_word_len 0.00206570902096\n",
      "prev_starts_upper= 0.0014700212981\n",
      "prev_is_brace 0.00102075691841\n",
      "prev_is_quote 0.00029823210718\n",
      "next_is_upper 0.000291203757549\n",
      "starts_with_space 0.0\n",
      "prec_words 0.0\n",
      "prev_len 0.0\n"
     ]
    }
   ],
   "source": [
    "print_importances(model, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
